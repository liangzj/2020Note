# 缓存的读写模式
业务系统读写缓存有以下3种模式：
+ Cache Aside (旁路缓存)
+ Read/Write Through （读写穿透）
+ Write Behind Caching (异步缓存写入)

| 功能项  | Cache Aside                 | Read/Write Through         | Write Behind Caching           |
| :---   |  :---                        |  :---                      |  :---                          | 
| 写流程 | 更新db,删除cache,db驱动cache更新 | cache不存在更新DB;cache存在更新cache+DB | 只更新缓存，缓存服务异步更新DB |
| 读流程 | miss后读db+回写                | miss后有缓存服务加载并写cache | miss后有缓存服务加载+写cache |
| 特点   | Lazy计算，以DB数据为准      | 存储数据复杂读写，隔离性更佳，热数据友好 |写性能最高，定期异步刷新，存在数据丢失概率 |
| 场景   | 强一致性 or 缓存数据构建复杂    | 数据有冷热区分                 | 写频率超高，需要合并批量操作  |

**备注：**  
+ Lazy计算：推迟计算，直到系统需要这个计算的结果。
+ 示例01（Cache Aside ）：  
缓存数据需要通过多个原始数据进行计算后设置。在部分数据变更后，直接删除缓存。同时，使用一个 Trigger 组件，实时读取 DB 的变更日志，然后重新计算并更新缓存。如果读缓存的时候，Trigger 还没写入 cache，则由调用方自行到 DB 加载计算并写入 cache。
+ 示例02(Read/Write Through):  
微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。
+ 实例03(Write Behind):  
比如一些计数业务，一条Feed被点赞 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。比如系统 Crash、机器宕机时，如果有数据还没保存到 DB，则会存在丢失的风险。所以这种读写模式适合变更频率特别高，但对一致性要求不太高的业务，这样写操作可以异步批量写入 DB，减小 DB 压力。

# 缓存的引入与架构设计
## 缓存组件选择
首先要根据需求选定相应的缓存组件，比如使用local-Cache，还是redis/Memcached等开源组件或者自定义开发新的缓存组件。

## 缓存数据结构设计
 确定好缓存组件，再根据业务访问的特定，进行相应缓存数据结构的设计。比如简单KV读写业务，可以封装成String/Json/Protocol Buffer格式，序列化成字节存入缓存，读取时先缓存服务读取字节再反序列化成相应格式再操作。对于只存取部分或需要缓存端计算的，可以设计成Hash/Set/List等。

 ## 缓存的分布设计
 前两步完成后，接下来需要考虑缓存的分布设计。主要是以下三个维度：
+ 选择分布式算法： 
    - 取模分布：优点简单，每个key只会存在确定节点；缺点如果某个节点故障会导致整体异常。
    - 一致性Hash分布：优点更稳健，如果部分节点故障，失效节点的数据访问均衡到其它存活节点。
+ 分布读写访问方案：
    - 缓存Client： 直接读写，性能最佳，但是需要client主动感知分布策略以及部署变化是及时作出相应响应，client相对复杂。
    - Proxy代理路由：分布逻辑及部署变更等由Proxy处理，业务应用直接访问Proxy，对开发友好。

+ 运行时的水平扩容和容灾方案： 考虑数据量增长过快时，如果做相应动态拆分以及水平扩展。分布式节点故障是迁移。

## 缓存架构部署及运维管理
主要考虑如何对缓存进行分池、分层、分IDC,以及是否需要异构处理。
+ 分池： 核心的、高并发访问的不同数据，需要分别拆分到独立缓存池中，规避相互影响；访问量小的、非核心业务数据可混用。
+ 分层： 对海量数据、访问操作10~100万级的业务数据，考虑分层，分摊访问量，避免个别节点过载。
+ 分IDC及异地多活： 考虑跨IDC的缓存数据更新同步问题。
+ 异构处理： 如果需要多种缓存组件组合使用，需考虑不同缓存组件间的异构同步处理。
+ 其它 ： 考虑缓存的服务化，集群管理、监控运维等。
